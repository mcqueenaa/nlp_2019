{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "m = MorphAnalyzer()\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for token in simple_word_tokenize(text):\n",
    "        lemmas.append(m.parse(token)[0].normal_form)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты взяты с сайта http://www.vokrugsveta.ru. Ключевые слова к текстам были указаны на сайте под каждой статьей. Всего 4 текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_names = ['текст 1', 'текст 2', 'текст 3', 'текст 4']\n",
    "keywords = {}\n",
    "my_keywords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Достаем тексты в переменную с текстами - texts, \n",
    "# а также мои и оригинальные ключевые слова лемматизируем и кладем в словари keywords и my_keywords соответственно\n",
    "texts = []\n",
    "for n in texts_names:\n",
    "    list_1 = []\n",
    "    list_2 = []\n",
    "    text = n + '.txt'\n",
    "    with open(text, 'r', encoding='utf-8') as t:\n",
    "        new_text = t.read()\n",
    "    lines = new_text.split('\\n')\n",
    "    for i in lines[0].split(': ')[1].split(', '):\n",
    "        list_1.append(normalize_text(i))\n",
    "    my_keywords[n] = list_1\n",
    "    for i in lines[1].split(': ')[1].split(', '):\n",
    "        list_2.append(normalize_text(i))\n",
    "    keywords[n] = list_2\n",
    "    texts.append(' '.join(lines[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'текст 1': ['авантюрный роман',\n",
       "  'берлин',\n",
       "  'стен',\n",
       "  'немецкий граница',\n",
       "  'гдр',\n",
       "  'фрг'],\n",
       " 'текст 2': ['уинстон черчилль',\n",
       "  'юсуф карша',\n",
       "  'фотография',\n",
       "  'фото',\n",
       "  'история один фотография',\n",
       "  'портрет',\n",
       "  'история',\n",
       "  'человек'],\n",
       " 'текст 3': ['фирменный блюдо', 'сладость', 'япония', 'вагаси'],\n",
       " 'текст 4': ['история', 'ограбление', 'живопись', 'искусство']}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ключевые слова с сайта\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'текст 1': ['берлинский стен', 'берлин', 'гдр', 'ссср'],\n",
       " 'текст 2': ['уинстон черчилль', 'черчилль', 'фотография', 'портрет', 'карша'],\n",
       " 'текст 3': ['десерт', 'сладость', 'япония', 'вагаси'],\n",
       " 'текст 4': ['картина', 'кража', 'искусство', 'шедевр']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ключевые слова, размеченные мной\n",
    "my_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, мои ключевые слова и ключевые слова с сайта очень похожи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точное пересечение моих ключевых слов и ключевых слов с сайта в тексте 0: {'берлин', 'гдр'}\n",
      "Точное пересечение моих ключевых слов и ключевых слов с сайта в тексте 1: {'фотография', 'уинстон черчилль', 'портрет'}\n",
      "Точное пересечение моих ключевых слов и ключевых слов с сайта в тексте 2: {'сладость', 'япония', 'вагаси'}\n",
      "Точное пересечение моих ключевых слов и ключевых слов с сайта в тексте 3: {'искусство'}\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(texts_names):\n",
    "    set_1 = set(keywords[j])\n",
    "    set_2 = set(my_keywords[j])\n",
    "    print('Точное пересечение моих ключевых слов и ключевых слов с сайта в тексте ' + str(i) + ': ' + str(set_1.intersection(set_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import RAKE\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выделим ключевые слова с помощью RAKE и оценим точность, полноту и F-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rake_keywords = {}\n",
    "for text, n in zip(texts, texts_names):\n",
    "    result = rake.run(normalize_text(text), maxWords=2, minFrequency=2)\n",
    "    new_result = []\n",
    "    for r in result:\n",
    "        if r[1] > 1: ## слова с рангом 1 и ниже были совсем дурацкие\n",
    "            new_result.append(r[0])\n",
    "    rake_keywords[n] = new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'текст 1': ['бернауэр-штрасса',\n",
       "  'заграничный паспорт',\n",
       "  'восточный берлин',\n",
       "  'территория гдр',\n",
       "  'берлинский стен',\n",
       "  'западный берлин',\n",
       "  'свобода выезд',\n",
       "  'это',\n",
       "  'граница',\n",
       "  'стрелять',\n",
       "  'выезд',\n",
       "  'страна',\n",
       "  'окно',\n",
       "  'западный',\n",
       "  'место',\n",
       "  'вступать',\n",
       "  'делать',\n",
       "  'пункт'],\n",
       " 'текст 2': ['это', 'черчилль'],\n",
       " 'текст 3': [],\n",
       " 'текст 4': ['служебный вход',\n",
       "  'мировой война',\n",
       "  'след преступник',\n",
       "  'сработать сигнализация',\n",
       "  'картина',\n",
       "  'время',\n",
       "  'удаться',\n",
       "  'это',\n",
       "  'найти',\n",
       "  'музей',\n",
       "  'весь',\n",
       "  'италия',\n",
       "  'написать',\n",
       "  'арестовать',\n",
       "  'похитить']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_keywords\n",
    "# ну как-то так себе, с третьим текстом вообще никак не справился...\n",
    "# хотя в 1 и 4 тексте есть штуки, похожие на ключевые слова, но все равно как-то плохо..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_prf(kw_true, kw_test):\n",
    "    prf_dict = {}\n",
    "    all_F1 = 0\n",
    "    for n in texts_names:\n",
    "        c = 0\n",
    "        for w in kw_true[n]:\n",
    "            if w in kw_test[n]:\n",
    "                c += 1\n",
    "        if c != 0:\n",
    "            P = c/len(kw_test[n])\n",
    "            R = c/len(kw_true[n])\n",
    "            F1 = 2 * ((P*R)/(P+R))\n",
    "        else:\n",
    "            P = 0\n",
    "            R = 0\n",
    "            F1 = 0\n",
    "            \n",
    "        prf_dict[n] = (P, R, F1)\n",
    "        all_F1 += F1\n",
    "    mean_F1 = all_F1/4\n",
    "    return prf_dict, mean_F1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применила функцию к своим ключевым словам, потому что с оригинальными во всех текстах точность и полнота были по нулям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_prf, rake_mean_F1 = count_prf(my_keywords, rake_keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слева направо: номер текста, точность, полнота, F-мера (via rake)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'текст 1': (0.05555555555555555, 0.25, 0.0909090909090909),\n",
       " 'текст 2': (0, 0, 0),\n",
       " 'текст 3': (0, 0, 0),\n",
       " 'текст 4': (0.06666666666666667, 0.25, 0.10526315789473685)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Слева направо: номер текста, точность, полнота, F-мера (via rake)')\n",
    "rake_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via rake): 0.04904306220095694\n"
     ]
    }
   ],
   "source": [
    "# хотя так тоже все довольно плохо получилось...\n",
    "print('Средняя по всем текстам F-мера (via rake): ' + str(rake_mean_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    text = re.sub(r'[A-Za-z]', '', text)\n",
    "    text = [m.normal_forms(x)[0] for x in text.split() if x not in\n",
    "            stop]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for t in texts:\n",
    "    corpus.append(' '.join(clean_text(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_matrix = X.toarray()\n",
    "tf_matrix = np.transpose(f_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(corpus)\n",
    "\n",
    "all_n = {}\n",
    "for word in words:\n",
    "    w_idx = words.index(word)\n",
    "    all_n[word] = np.count_nonzero(tf_matrix[w_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_idf_matrix(tf_matrix, N, all_n, words):\n",
    "    tf_idf_matrix = []\n",
    "    for idx, doc in enumerate(corpus):\n",
    "        tf_idf_matrix.append([])\n",
    "        for word in words:\n",
    "            tf_idf = 0\n",
    "            if word in doc:\n",
    "                w_idx = words.index(word)\n",
    "                d_idx = corpus.index(doc)\n",
    "                tf = tf_matrix[w_idx][d_idx]/len(doc)\n",
    "                n = all_n[word]\n",
    "                idf = log(N/n)\n",
    "                tf_idf = tf * idf\n",
    "            tf_idf_matrix[idx].append(tf_idf)\n",
    "    return np.array(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_matrix = create_tf_idf_matrix(tf_matrix, N, all_n, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.73161450e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        6.91073959e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.25430148e-04],\n",
       "       [1.54375764e-04, 7.71878820e-05, 3.08751528e-04, ...,\n",
       "        0.00000000e+00, 1.54375764e-04, 0.00000000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006910739586838936"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002185291603735788"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00027316, 0.        , ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_keywords = {}\n",
    "for name, arr in zip(texts_names, tf_idf_matrix):\n",
    "    result = []\n",
    "    for word, score in zip(words, arr):\n",
    "        if score > 0.0015:\n",
    "            result.append(word)\n",
    "    tf_idf_keywords[name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'текст 1': ['берлин', 'гдр', 'западный', 'стен'],\n",
       " 'текст 2': ['великобритания',\n",
       "  'кадр',\n",
       "  'карша',\n",
       "  'премьера',\n",
       "  'премьерминистр',\n",
       "  'сигара',\n",
       "  'снимка',\n",
       "  'фотограф',\n",
       "  'фотография',\n",
       "  'черчилль'],\n",
       " 'текст 3': ['десерт',\n",
       "  'использовать',\n",
       "  'колобок',\n",
       "  'маттить',\n",
       "  'паста',\n",
       "  'рисовый',\n",
       "  'фасоль',\n",
       "  'церемония',\n",
       "  'чай',\n",
       "  'чайный',\n",
       "  'японский'],\n",
       " 'текст 4': ['картина', 'кража', 'музей', 'похитить']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Как будто бы получилось даже лучше, чем с RAKE, несмотря на то, что tf-idf не выделяет словосочетания\n",
    "tf_idf_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посчитаем точность, полноту и Ф-меру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_prf, tf_idf_mean_F1 = count_prf(keywords, tf_idf_keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слева направо: номер текста, точность, полнота, F-мера (via tf_idf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'текст 1': (0.75, 0.5, 0.6),\n",
       " 'текст 2': (0.1, 0.125, 0.11111111111111112),\n",
       " 'текст 3': (0, 0, 0),\n",
       " 'текст 4': (0, 0, 0)}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Слева направо: номер текста, точность, полнота, F-мера (via tf_idf)')\n",
    "tf_idf_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via tf_idf): 0.17777777777777778\n"
     ]
    }
   ],
   "source": [
    "print('Средняя по всем текстам F-мера (via tf_idf): ' + str(tf_idf_mean_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_prf, tf_idf_mean_F1 = count_prf(my_keywords, tf_idf_keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слева направо: номер текста, точность, полнота, F-мера (via tf_idf в сравнении с моими ключевыми словами)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'текст 1': (0.5, 0.5, 0.5),\n",
       " 'текст 2': (0.3, 0.6, 0.4),\n",
       " 'текст 3': (0.09090909090909091, 0.25, 0.13333333333333333),\n",
       " 'текст 4': (0.5, 0.5, 0.5)}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Слева направо: номер текста, точность, полнота, F-мера (via tf_idf в сравнении с моими ключевыми словами)')\n",
    "tf_idf_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via tf_idf в сравнении с моими ключевыми словами): 0.38333333333333336\n"
     ]
    }
   ],
   "source": [
    "print('Средняя по всем текстам F-мера (via tf_idf в сравнении с моими ключевыми словами): ' + str(tf_idf_mean_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "С моими ключевыми словами получается как-то поближе, чем с оригинальными..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь попробуем TextRank с библиотекой summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords as kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "summa_keywords = {}\n",
    "for text, n in zip(texts, texts_names):\n",
    "    result = kw.keywords(normalize_text(text), additional_stopwords=stop, scores=True)\n",
    "    new_result = []\n",
    "    for r in result:\n",
    "        if r[1] > 0.14: \n",
    "            new_result.append(r[0])\n",
    "    summa_keywords[n] = new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'текст 1': ['год', 'гдр', 'человек', 'шабовск', 'стен', 'это', 'граница'],\n",
       " 'текст 2': ['черчилль фотограф',\n",
       "  'премьер',\n",
       "  'портрет',\n",
       "  'сигара',\n",
       "  'юсуф карша'],\n",
       " 'текст 3': ['десерт', 'японский сладость', 'чайный'],\n",
       " 'текст 4': ['год', 'самый знаменитый картина', 'полиция', 'однако']}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summa_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как-то странно он выделил ключевые слова, вроде близко к правде, но очень криво... В четвертом тексте вообще получилось плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summa_prf, summa_mean_F1 = count_prf(keywords, summa_keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слева направо: номер текста, точность, полнота, F-мера (via summa)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'текст 1': (0.2857142857142857, 0.3333333333333333, 0.30769230769230765),\n",
       " 'текст 2': (0.4, 0.25, 0.3076923076923077),\n",
       " 'текст 3': (0, 0, 0),\n",
       " 'текст 4': (0, 0, 0)}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Слева направо: номер текста, точность, полнота, F-мера (via summa)')\n",
    "summa_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via summa): 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "print('Средняя по всем текстам F-мера (via summa): ' + str(summa_mean_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summa_prf, summa_mean_F1 = count_prf(my_keywords, summa_keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слева направо: номер текста, точность, полнота, F-мера (via summa в сравнении с моими ключевыми словами)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'текст 1': (0.14285714285714285, 0.25, 0.18181818181818182),\n",
       " 'текст 2': (0.2, 0.2, 0.20000000000000004),\n",
       " 'текст 3': (0.3333333333333333, 0.25, 0.28571428571428575),\n",
       " 'текст 4': (0, 0, 0)}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Слева направо: номер текста, точность, полнота, F-мера (via summa в сравнении с моими ключевыми словами)')\n",
    "summa_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via summa в сравнении с моими ключевыми словами): 0.1668831168831169\n"
     ]
    }
   ],
   "source": [
    "print('Средняя по всем текстам F-мера (via summa в сравнении с моими ключевыми словами): ' + str(summa_mean_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь с моими ключевыми словами тоже получилось лучше, чем с оригинальными, хоть и не слишком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз посмотрим на средние F-мер по всем 4-м текстам (в сравнении тестовых кл. слов с выделенными мной ключевыми словами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя по всем текстам F-мера (via RAKE в сравнении с моими ключевыми словами): 0.04904306220095694\n",
      "Средняя по всем текстам F-мера (via tf-idf в сравнении с моими ключевыми словами): 0.38333333333333336\n",
      "Средняя по всем текстам F-мера (via summa в сравнении с моими ключевыми словами): 0.1668831168831169\n"
     ]
    }
   ],
   "source": [
    "print('Средняя по всем текстам F-мера (via RAKE в сравнении с моими ключевыми словами): ' + str(rake_mean_F1))\n",
    "print('Средняя по всем текстам F-мера (via tf-idf в сравнении с моими ключевыми словами): ' + str(tf_idf_mean_F1))\n",
    "print('Средняя по всем текстам F-мера (via summa в сравнении с моими ключевыми словами): ' + str(summa_mean_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но лучше всего справился примитивный tf-idf (несмотря на то, что он выделяет только по одному слову, а словосочетания не выделяет), а rake справился совсем ужасно (практически никак).\n",
    "Хотя в целом цифры все равно довольно печальные.\n",
    "\n",
    "Есть проблемы с лемматизацией, особенно имен собственных, из-за чего, как минимум, textRank'у засчиталась ошибка к точности.\n",
    "Rake выделяет слишком много всего в одних текстах, и наоборот - почти ничего в других. Не очень понятно, почему так происходит...\n",
    "Tf-idf в принципе выделяет ключевые слова неплохо, но также есть проблемы с лемматизацией в некоторых местах (премьер, премьер-министр). По смыслу выделенные tf-idf'ом слова в большинстве случаев вполне соответствуют истине, но все же их многовато, т.к. все-таки он работает через частоты слов + оценивает их встречаемость в других текстах, а корпус у нас маленький и тексты довольно разные. М.б. на бОльшем корпусе он сработал бы лучше.\n",
    "TextRank с виду, вроде бы, тоже выделяет не так уж и ужасно, в принципе соответствуя действительности (кроме, разве что, 4 текста). Но местами есть проблемы с лемматизацией - \"юсуф карша\", а также непонятные словосочетания - \"черчилль фотограф\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
